{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libs\n",
    "from math import sqrt\n",
    "import random\n",
    "import os\n",
    "\n",
    "#default data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modules for data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/2year.xlsx')\n",
    "data['B'] = (data['B'].index > 9772).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.25366</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.3440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.2381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.31877</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16499</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.4660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29358</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.0066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.10823</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10124</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.9874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2        X3      X4      X5        X6       X7       X8  \\\n",
       "0  0.202350  0.46500  0.240380  1.5171 -14.547  0.510690  0.25366  0.91816   \n",
       "1  0.030073  0.59563  0.186680  1.3382 -37.859 -0.000319  0.04167  0.67890   \n",
       "2  0.257860  0.29949  0.665190  3.2211  71.799  0.000000  0.31877  2.33200   \n",
       "3  0.227160  0.67850  0.042784  1.0828 -88.212  0.000000  0.28505  0.47384   \n",
       "4  0.085443  0.38039  0.359230  1.9444  21.731  0.187900  0.10823  1.37140   \n",
       "\n",
       "        X9      X10  ...      X56       X57      X58      X59     X60  \\\n",
       "0  1.15190  0.42695  ...  0.13184  0.473950  0.86816  0.00024  8.5487   \n",
       "1  0.32356  0.40437  ...  0.12146  0.074369  0.87235  0.00000  1.5264   \n",
       "2  1.67620  0.69841  ...  0.16499  0.369210  0.81614  0.00000  4.3325   \n",
       "3  1.32410  0.32150  ...  0.29358  0.706570  0.78617  0.48456  5.2309   \n",
       "4  1.11260  0.52167  ...  0.10124  0.163790  0.89876  0.00000  5.7035   \n",
       "\n",
       "       X61      X62      X63      X64  B  \n",
       "0  5.16550  107.740  3.38790   5.3440  0  \n",
       "1  0.63305  622.660  0.58619   1.2381  0  \n",
       "2  3.19850   65.215  5.59690  47.4660  0  \n",
       "3  5.06750  142.460  2.56210   3.0066  0  \n",
       "4  4.00200   89.058  4.09840   5.9874  0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_headers(df):\n",
    "    cols = ['X' + str(i+1) for i in range(len(df.columns)-1)]\n",
    "    cols.append('Y')\n",
    "    df.columns = cols\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "mean_imputed_df = pd.DataFrame(imputer.fit_transform(data))\n",
    "set_new_headers(mean_imputed_df)\n",
    "\n",
    "data_imp = pd.DataFrame()\n",
    "\n",
    "X = mean_imputed_df.iloc[:, :-1]\n",
    "Y = mean_imputed_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131840</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.7400</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.34400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121460</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.6600</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.23810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318770</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164990</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.2150</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.46600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285050</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293580</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.484560</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.4600</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.00660</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.108230</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101240</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.0580</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.98740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.287840</td>\n",
       "      <td>0.55225</td>\n",
       "      <td>0.316340</td>\n",
       "      <td>1.7033</td>\n",
       "      <td>38.803</td>\n",
       "      <td>0.390120</td>\n",
       "      <td>0.287840</td>\n",
       "      <td>0.80761</td>\n",
       "      <td>1.29200</td>\n",
       "      <td>0.44600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225990</td>\n",
       "      <td>0.645370</td>\n",
       "      <td>0.77401</td>\n",
       "      <td>0.229690</td>\n",
       "      <td>7.8151</td>\n",
       "      <td>3.15340</td>\n",
       "      <td>110.8300</td>\n",
       "      <td>3.29330</td>\n",
       "      <td>6.33460</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.153820</td>\n",
       "      <td>0.47248</td>\n",
       "      <td>0.311790</td>\n",
       "      <td>1.6898</td>\n",
       "      <td>-71.985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190810</td>\n",
       "      <td>1.11650</td>\n",
       "      <td>1.50460</td>\n",
       "      <td>0.52752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142170</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.87368</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>2.6734</td>\n",
       "      <td>7.80930</td>\n",
       "      <td>109.6400</td>\n",
       "      <td>3.32910</td>\n",
       "      <td>6.36920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>0.45834</td>\n",
       "      <td>0.417040</td>\n",
       "      <td>1.9406</td>\n",
       "      <td>47.511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>1.18180</td>\n",
       "      <td>2.18540</td>\n",
       "      <td>0.54166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625180</td>\n",
       "      <td>0.484660</td>\n",
       "      <td>0.38590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.7696</td>\n",
       "      <td>4.57600</td>\n",
       "      <td>74.0550</td>\n",
       "      <td>4.92880</td>\n",
       "      <td>15.65800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079147</td>\n",
       "      <td>0.02240</td>\n",
       "      <td>0.897050</td>\n",
       "      <td>283.1200</td>\n",
       "      <td>139.750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097916</td>\n",
       "      <td>43.64300</td>\n",
       "      <td>0.61657</td>\n",
       "      <td>0.97760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168460</td>\n",
       "      <td>0.080961</td>\n",
       "      <td>0.86061</td>\n",
       "      <td>0.014807</td>\n",
       "      <td>14.2180</td>\n",
       "      <td>79.20300</td>\n",
       "      <td>1.8823</td>\n",
       "      <td>193.91000</td>\n",
       "      <td>6.17980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.71174</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>1.1485</td>\n",
       "      <td>-62.297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>0.40500</td>\n",
       "      <td>1.17380</td>\n",
       "      <td>0.28826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203090</td>\n",
       "      <td>0.034347</td>\n",
       "      <td>0.83056</td>\n",
       "      <td>0.720470</td>\n",
       "      <td>7.7605</td>\n",
       "      <td>4.12530</td>\n",
       "      <td>136.5400</td>\n",
       "      <td>2.67320</td>\n",
       "      <td>2.36800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.145320</td>\n",
       "      <td>0.76682</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>1.2722</td>\n",
       "      <td>-90.839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185480</td>\n",
       "      <td>0.30409</td>\n",
       "      <td>2.04450</td>\n",
       "      <td>0.23318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.623210</td>\n",
       "      <td>0.90936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.1457</td>\n",
       "      <td>6.64480</td>\n",
       "      <td>136.9000</td>\n",
       "      <td>2.66620</td>\n",
       "      <td>83.52800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>0.52424</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.3215</td>\n",
       "      <td>-25.687</td>\n",
       "      <td>-0.494160</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>0.90753</td>\n",
       "      <td>3.24570</td>\n",
       "      <td>0.47576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293490</td>\n",
       "      <td>0.164660</td>\n",
       "      <td>0.70790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>9.12930</td>\n",
       "      <td>58.0220</td>\n",
       "      <td>6.29070</td>\n",
       "      <td>10.20200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-0.044460</td>\n",
       "      <td>0.11409</td>\n",
       "      <td>0.151960</td>\n",
       "      <td>2.3319</td>\n",
       "      <td>-48.066</td>\n",
       "      <td>-0.127010</td>\n",
       "      <td>-0.040333</td>\n",
       "      <td>6.90290</td>\n",
       "      <td>0.94472</td>\n",
       "      <td>0.78755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058513</td>\n",
       "      <td>-0.056453</td>\n",
       "      <td>1.05850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.1880</td>\n",
       "      <td>19.10600</td>\n",
       "      <td>69.1190</td>\n",
       "      <td>5.28080</td>\n",
       "      <td>0.82087</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.179490</td>\n",
       "      <td>0.42473</td>\n",
       "      <td>0.552350</td>\n",
       "      <td>2.4516</td>\n",
       "      <td>42.408</td>\n",
       "      <td>0.553430</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>1.35440</td>\n",
       "      <td>1.10230</td>\n",
       "      <td>0.57527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092802</td>\n",
       "      <td>0.312010</td>\n",
       "      <td>0.90720</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>9.3788</td>\n",
       "      <td>4.90680</td>\n",
       "      <td>53.7340</td>\n",
       "      <td>6.79270</td>\n",
       "      <td>38.49200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.20223</td>\n",
       "      <td>0.169850</td>\n",
       "      <td>3.1563</td>\n",
       "      <td>92.043</td>\n",
       "      <td>0.426760</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>3.94480</td>\n",
       "      <td>1.27470</td>\n",
       "      <td>0.79777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215480</td>\n",
       "      <td>0.156190</td>\n",
       "      <td>0.78452</td>\n",
       "      <td>0.154760</td>\n",
       "      <td>9.7697</td>\n",
       "      <td>3.14200</td>\n",
       "      <td>51.8240</td>\n",
       "      <td>7.04310</td>\n",
       "      <td>0.73834</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1       X2        X3        X4       X5        X6        X7  \\\n",
       "0   0.202350  0.46500  0.240380    1.5171  -14.547  0.510690  0.253660   \n",
       "1   0.030073  0.59563  0.186680    1.3382  -37.859 -0.000319  0.041670   \n",
       "2   0.257860  0.29949  0.665190    3.2211   71.799  0.000000  0.318770   \n",
       "3   0.227160  0.67850  0.042784    1.0828  -88.212  0.000000  0.285050   \n",
       "4   0.085443  0.38039  0.359230    1.9444   21.731  0.187900  0.108230   \n",
       "5   0.287840  0.55225  0.316340    1.7033   38.803  0.390120  0.287840   \n",
       "6   0.153820  0.47248  0.311790    1.6898  -71.985  0.000000  0.190810   \n",
       "7   0.262520  0.45834  0.417040    1.9406   47.511  0.000000  0.262520   \n",
       "8   0.079147  0.02240  0.897050  283.1200  139.750  0.000000  0.097916   \n",
       "9   0.009901  0.71174  0.065186    1.1485  -62.297  0.000000  0.013459   \n",
       "10  0.145320  0.76682  0.208700    1.2722  -90.839  0.000000  0.185480   \n",
       "11  0.078337  0.52424  0.165900    1.3215  -25.687 -0.494160  0.078337   \n",
       "12 -0.044460  0.11409  0.151960    2.3319  -48.066 -0.127010 -0.040333   \n",
       "13  0.179490  0.42473  0.552350    2.4516   42.408  0.553430  0.223930   \n",
       "14  0.124600  0.20223  0.169850    3.1563   92.043  0.426760  0.147910   \n",
       "\n",
       "          X8       X9      X10  ...       X56       X57      X58       X59  \\\n",
       "0    0.91816  1.15190  0.42695  ...  0.131840  0.473950  0.86816  0.000240   \n",
       "1    0.67890  0.32356  0.40437  ...  0.121460  0.074369  0.87235  0.000000   \n",
       "2    2.33200  1.67620  0.69841  ...  0.164990  0.369210  0.81614  0.000000   \n",
       "3    0.47384  1.32410  0.32150  ...  0.293580  0.706570  0.78617  0.484560   \n",
       "4    1.37140  1.11260  0.52167  ...  0.101240  0.163790  0.89876  0.000000   \n",
       "5    0.80761  1.29200  0.44600  ...  0.225990  0.645370  0.77401  0.229690   \n",
       "6    1.11650  1.50460  0.52752  ...  0.142170  0.291600  0.87368  0.030421   \n",
       "7    1.18180  2.18540  0.54166  ...  0.625180  0.484660  0.38590  0.000000   \n",
       "8   43.64300  0.61657  0.97760  ...  0.168460  0.080961  0.86061  0.014807   \n",
       "9    0.40500  1.17380  0.28826  ...  0.203090  0.034347  0.83056  0.720470   \n",
       "10   0.30409  2.04450  0.23318  ...  0.130540  0.623210  0.90936  0.000000   \n",
       "11   0.90753  3.24570  0.47576  ...  0.293490  0.164660  0.70790  0.000000   \n",
       "12   6.90290  0.94472  0.78755  ... -0.058513 -0.056453  1.05850  0.000000   \n",
       "13   1.35440  1.10230  0.57527  ...  0.092802  0.312010  0.90720  0.076880   \n",
       "14   3.94480  1.27470  0.79777  ...  0.215480  0.156190  0.78452  0.154760   \n",
       "\n",
       "        X60       X61       X62        X63       X64    Y  \n",
       "0    8.5487   5.16550  107.7400    3.38790   5.34400  0.0  \n",
       "1    1.5264   0.63305  622.6600    0.58619   1.23810  0.0  \n",
       "2    4.3325   3.19850   65.2150    5.59690  47.46600  0.0  \n",
       "3    5.2309   5.06750  142.4600    2.56210   3.00660  0.0  \n",
       "4    5.7035   4.00200   89.0580    4.09840   5.98740  0.0  \n",
       "5    7.8151   3.15340  110.8300    3.29330   6.33460  0.0  \n",
       "6    2.6734   7.80930  109.6400    3.32910   6.36920  0.0  \n",
       "7    7.7696   4.57600   74.0550    4.92880  15.65800  0.0  \n",
       "8   14.2180  79.20300    1.8823  193.91000   6.17980  0.0  \n",
       "9    7.7605   4.12530  136.5400    2.67320   2.36800  0.0  \n",
       "10   3.1457   6.64480  136.9000    2.66620  83.52800  0.0  \n",
       "11  12.6000   9.12930   58.0220    6.29070  10.20200  0.0  \n",
       "12   3.1880  19.10600   69.1190    5.28080   0.82087  0.0  \n",
       "13   9.3788   4.90680   53.7340    6.79270  38.49200  0.0  \n",
       "14   9.7697   3.14200   51.8240    7.04310   0.73834  0.0  \n",
       "\n",
       "[15 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputed_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using smote to balance data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=10)\n",
    "smote = SMOTE(random_state=32)\n",
    "X_train_sm, y_train_sm= smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "nfolds = 10\n",
    "nclass = 2\n",
    "ntrain = X_train_sm.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=nfolds, random_state=20, shuffle=True)\n",
    "cross_val = StratifiedKFold(nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model objects\n",
    "## Tuning model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=4)]: Done  90 out of  90 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_params = {\"C\": [0.5, 0.55, 0.6],\n",
    "                 \"solver\": ['newton-cg', 'sag', 'saga']}\n",
    "\n",
    "lr_grid = GridSearchCV(log_reg, log_reg_params, cv=cross_val, refit=True, verbose=1, n_jobs=4)\n",
    "\n",
    "lr_grid.fit(X_train_sm, y_train_sm)\n",
    "lr_best_est = lr_grid.best_estimator_\n",
    "\n",
    "print(\"Accuracy (LogisticRegression): {} with params {}\".format(lr_grid.best_score_, lr_best_est))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeClassifier()\n",
    "d_tree_params = {'criterion': ['gini'],\n",
    "                'max_depth': [50, 60, 70],\n",
    "                'max_leaf_nodes': [100, 125, 150]}\n",
    "\n",
    "dt_grid = GridSearchCV(d_tree, d_tree_params, cv=cross_val, refit=True, verbose=1, n_jobs=4)\n",
    "dt_grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "dt_best_est = dt_grid.best_estimator_\n",
    "print(\"Accuracy (Decision tree): {} with params {}\".format(dt_grid.best_score_, dt_best_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_forest = RandomForestClassifier()\n",
    "r_forest_params = {'n_estimators': [150,200],\n",
    "                'criterion': ['gini'],\n",
    "                'max_depth': [25, 50],\n",
    "                'max_features': [64],\n",
    "                'max_leaf_nodes': [10, 25],\n",
    "                'bootstrap': [True]}\n",
    "\n",
    "#r_forest_grid = GridSearchCV(r_forest, r_forest_params, cv=cross_val, refit=True, verbose=1, n_jobs=4)\n",
    "#r_forest_grid.fit(X_train_sm, y_train_sm)\n",
    "rf_random_grid = RandomizedSearchCV(r_forest, r_forest_params, cv=cross_val, refit=True, verbose=1, n_jobs=-1)\n",
    "rf_random_grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "rf_best_est = rf_random_grid.best_estimator_\n",
    "print(\"Accuracy (Random forest): {} with params {}\".format(rf_random_grid.best_score_, rf_best_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SVM classifier Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ\n",
    "#\n",
    "\n",
    "\n",
    "#svm = SVC()\n",
    "#svm_params = {'kernel': ['linear', 'poly'],\n",
    "#                'probability': [True],\n",
    "#                'decision_function_shape': ['ovo']}\n",
    "\n",
    "#svm_grid = GridSearchCV(svm, svm_params, cv=cross_val, refit=True, verbose=1, n_jobs=-1)\n",
    "#svm_grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "#svm_grid = RandomizedSearchCV(svm, svm_params, cv=cross_val, refit=True, verbose=1, n_jobs=-1)\n",
    "#svm_grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "#svm_best_est = svm_grid.best_estimator_\n",
    "#print(\"Accuracy (SVM): {} with params {}\".format(svm_grid.best_score_, svm_best_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "xg_params = {\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eta': [0.3, 0,5],\n",
    "    'objective': ['binary:logitraw', 'binary:hinge'],\n",
    "    'gamma':[0,1],\n",
    "    'max_depth': [8],\n",
    "    'learning_rate': [0.1, 0.15]\n",
    "}\n",
    "\n",
    "#xgb_grid = GridSearchCV(xgboost, xg_params, cv=cross_val, refit=True, verbose=1, n_jobs=4)\n",
    "#xgb_grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "xgb_grid = RandomizedSearchCV(xgboost, xg_params, cv=cross_val, refit=True, verbose=1, n_jobs=-1)\n",
    "xgb_grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "xgb_best_est = xgb_grid.best_estimator_\n",
    "print(\"Accuracy (XGboosting): {} with params {}\".format(xgb_grid.best_score_, xgb_best_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(model, features):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    results=pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\n",
    "    results=results.sort_values('importance', ascending=False)\n",
    "    print(results.head(10))\n",
    "    results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh',\n",
    "                     color = 'red', edgecolor = 'k', title = 'Feature Importances')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain=X_train_sm.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "nclass = 2\n",
    "SEED = 42\n",
    "NFOLDS = 10\n",
    "\n",
    "kf = KFold(n_splits=NFOLDS, random_state=SEED, shuffle=True)\n",
    "labels = ['Normal','Bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    print(Xr_train, Xr_test, tr_ind)\n",
    "    \n",
    "    for i, (train, test) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        clf.fit(X_train[train], y_train[train])\n",
    "        sc = clf.score(X_train[test], y_train[test])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[test] = clf.predict_proba(X_train[test])\n",
    "        Xr_test += clf.predict_proba(X_test, validate_features=False)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(Xr, y, labels, best, nclass):\n",
    "    pred=[]\n",
    "    for x in Xr:\n",
    "        if x > best:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    print(classification_report(y,pred, target_names=labels, digits=4))\n",
    "    print(confusion_matrix(y, pred, labels=range(nclass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_auc(y_train_set, pred_train_set):\n",
    "    thresholds = np.linspace(0.01, 0.5, 1000)\n",
    "    f1_sc = np.array([f1_score(y_train_set, pred_train_set[:,1] > thr) for thr in thresholds])\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(thresholds, f1_sc, linewidth=4)\n",
    "    plt.ylabel(\"F1 score\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    \n",
    "    best_model_f1 = thresholds[f1_sc.argmax()]\n",
    "    \n",
    "    return best_model_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best = LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "pred_train, pred_test=BuildModel(lr_best, X_train_sm, y_train_sm, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc = np.array([f1_score(y_train_sm,pred_train[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "#plt.savefig(\"Xgb-thr.jpg\", dpi=300)\n",
    "best_lr_f1 = thresholds[f1_sc.argmax()]\n",
    "print(f1_sc.max())\n",
    "print(best_lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train[:,1],y_train_sm, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
    "                       max_features=None, max_leaf_nodes=150,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=None, splitter='best')\n",
    "pred_train_dt, pred_test_dt=BuildModel(dt_best, X_train_sm, y_train_sm, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_dt = np.array([f1_score(y_train_sm,pred_train_dt[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_dt, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "#plt.savefig(\"Xgb-thr.jpg\", dpi=300)\n",
    "best_dt_f1 = thresholds[f1_sc_dt.argmax()]\n",
    "print(f1_sc_dt.max())\n",
    "print(best_dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_dt[:,1],y_train_sm, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=25, max_features=64, max_leaf_nodes=25,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "pred_train_rf, pred_test_rf = BuildModel(rf_best, X_train_sm, y_train_sm, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_rf = np.array([f1_score(y_train_sm,pred_train_rf[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_rf, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_rf_f1 = thresholds[f1_sc_rf.argmax()]\n",
    "print('f1 score of random forest: ', f1_sc_rf.max())\n",
    "print(best_rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_rf[:,1],y_train_sm, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eta=5, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logitraw', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "pred_train_xgb, pred_test_xgb = BuildModel(xgb_best, X_train_sm, y_train_sm, X_test, kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_xgb = np.array([f1_score(y_train_sm,pred_train_xgb[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_xgb, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_xgb = thresholds[f1_sc_xgb.argmax()]\n",
    "print(f1_sc_xgb.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_xgb[:,1],y_train_sm, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
